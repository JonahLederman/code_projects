Name: Jonah Lederman, Haziel Cerroblanco

Date: 11/6/2025

Subject: Dijkstra’s Algorithm Implementation Paper

The first implementation of the algorithm is of the straightforward implementation described in the textbook. For the most part, the implementation is very similar to the pseudocode given for it. It initializes the length of each vertex, setting them all to pseudo-infinity while leaving the starting vertex zero. I also set the starting vertex as explored/visited. Then, I iterate V - 1 times to create the list of distances. In the implementation I created, I iterated through every edge that exists to get the shortest length, which causes a major issue that will be discussed shortly. Another major modification would be how I created classes for both vertices and edges, using them to store exploration states and directionality, respectively. This is unlike the way the book uses only arrays to store the edges. Apart from that, I believe my algorithm is following what the instructions for the implementation is describing.

The time complexity of the straightforward algorithm is intended to be O(n^2) (or O(V^2), where |V| is the amount of vertices that exist). However, the way I coded the algorithm, it multiplies the time complexity by M, as I am looping through every edge, causing the final time complexity to be O(V^2 * M) (similar to O(n^3)). This is pretty bad, but I had tried to figure out how to fix it for a couple of days, with help from classmates, but ended up with no solution. So, in this case, my predicted time-complexity for the algorithm would be O(V^2 * M).
The second-implementation of the algorithm was made using Python and used a Heap data structure to implement Dijekstra's Algorithm. I set up a priority queue to check the vertices and its edges, and I created a list of edges which was the size of the number of vertices. When using the textbook to construct this algorithm, I had to make some modifications to the pseudocode that was given. Specifically, instead of adding all the vertices into a set before the loop began, I added the vertices for each iteration of the loop, looking at a specific vertex and its edges each time. In addition, the book didn’t include a method to translate a .txt file into an adjacency list, which I was using for my adjacency lists. This caused some issues with the code, so I had to make my own method to translate a .txt file into a usable list. As I input the challenge set after making the regular set work, I discovered that the book also assumed that I already knew the number of vertices, but my program didn’t know that until I manually put in the number of vertices. This practice is not good for real-world applications, so I made a function to determine the number of vertices in the file provided, which took some understanding, but with enough time I was able to create a working function for my purpose.

In order to determine time complexity, I had to do two things. First, look at the code and determine how many iterable loops are occurring, and secondly, add counters to my code in order to help me further understand the process behind it. My results? I ended up going through the inner loop 16 times. With only eight vertices and two edges per vertex, that means that my algorithm ended up taking twice as long as there were edges, so in this case, m * n, where m is the number of edges and n is the number of vertices. Therefore the time complexity for this implementation is O(mn). 

Comparing the two algorithms and their predicted performance, we can determine that the heap implementation of this algorithm ended up taking less time to run, as it took less steps than the non-heap implementation. In total, the heap algorithm only took 16 steps, while the non-heap algorithm took a total of 112 steps. The result of these tests shows that using a heap data structure is faster than not using one. We also have to consider the fact that the heap data structure implementation was made in Python while the non-heap implementation was made in Java, but I believe that even if both implementations were in the same language, the logic would still be the same and therefore the heap implementation would be faster.

To verify that our algorithms worked with any kind of dataset that we give it (that would normally work for Dijkstra’s algorithm), we used both datasets given by Algorithms Illuminated, along with datasets we have created ourselves. The test data was simple, as it seemed to work perfectly, as all distances were correct. The challenge data, though, is harder to verify due to the size of it, but considering the other data files we used, it’s most likely working well with it, too. We created three data files: denseTest, fullyDenseTest, and sparseTest. The denseTest.txt file showed us if our algorithms worked with a dense amount of edges in a graph. We compared each of our algorithms to find that they matched, and it seemed to have been correct according to our own hand-made calculations. The same went for the fullyDenseTest.txt file, showing us it worked with a graph where every vertex was connected to each other by an edge. The spareTest.txt file contained a couple of vertices that had no paths to the starting vertex. This way we can make sure our algorithms account for such cases, and it sets the distance for such vertices as inf (or the max integer limit). Therefore, with these tests, it’s likely that our algorithm works as intended (even if the time-complexity is flawed).
